{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 读取数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train_data = pd.read_csv('train_all.csv',nrows=10000)\n",
    "test_data = pd.read_csv('test_all.csv',nrows=100)\n",
    "features_columns = [col for col in train_data.columns if col not in ['user_id','label']]\n",
    "train = train_data[features_columns].values\n",
    "test = test_data[features_columns].values\n",
    "target =train_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 缺失值补全\n",
    "处理缺失值有很多方法，最常用为以下几种：\n",
    "1 填充。（本案例所用方法）通用的方法是采用平均数、中位数来填充，可以适用插值或者模型预测的方法进行缺失补全。\n",
    "2 删除。当数据量较大时，或者缺失数据占比较小时，可以使用这种方法。\n",
    "3 不处理。树类模型对缺失值不明感。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(strategy=\"median\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(train)\n",
    "train_imputer = imputer.transform(train)\n",
    "test_imputer = imputer.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 特征选择\n",
    "在机器学习和统计学中，特征选择（英语：feature selection）也被称为变量选择、属性选择 或变量子集选择 。它是指：为了构建模型而选择相关特征（即属性、指标）子集的过程。使用特征选择技术有三个原因：\n",
    "\n",
    "简化模型，使之更易于被研究人员或用户理解，\n",
    "缩短训练时间，\n",
    "改善通用性、降低过拟合（即降低方差）。\n",
    "要使用特征选择技术的关键假设是：训练数据包含许多冗余 或无关 的特征，因而移除这些特征并不会导致丢失信息。 冗余 或无关 特征是两个不同的概念。如果一个特征本身有用，但如果这个特征与另一个有用特征强相关，且那个特征也出现在数据中，那么这个特征可能就变得多余。 特征选择技术与特征提取有所不同。特征提取是从原有特征的功能中创造新的特征，而特征选择则只返回原有特征中的子集。 特征选择技术的常常用于许多特征但样本（即数据点）相对较少的领域。特征选择应用的典型用例包括：解析书面文本和微阵列数据，这些场景下特征成千上万，但样本只有几十到几百个。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 验证特征选择有效函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def feature_selection(train, train_sel, target):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "\n",
    "    scores = cross_val_score(clf, train, target, cv=5)\n",
    "    scores_sel = cross_val_score(clf, train_sel, target, cv=5)\n",
    "\n",
    "    print(\"No Select Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print(\"Features Select Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 删除方差较小的要素（方法一）\n",
    "VarianceThreshold是一种简单的基线特征选择方法。它会删除方差不符合某个阈值的所有要素。默认情况下，它会删除所有零方差要素，即在所有样本中具有相同值的要素。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据未特征筛选维度 (2000, 229)\n",
      "训练数据特征筛选维度后 (2000, 25)\n",
      "[[1.487e+03 6.000e+00 1.000e+00 ... 3.100e+02 3.100e+02 2.180e+02]\n",
      " [1.590e+02 5.000e+00 0.000e+00 ... 2.740e+02 2.740e+02 2.330e+02]\n",
      " [3.020e+02 5.000e+00 1.000e+00 ... 2.780e+02 2.780e+02 1.460e+02]\n",
      " ...\n",
      " [4.950e+03 4.000e+00 1.000e+00 ... 8.400e+01 8.400e+01 5.500e+01]\n",
      " [1.582e+03 3.000e+00 1.000e+00 ... 9.200e+01 9.200e+01 6.300e+01]\n",
      " [2.066e+03 4.000e+00 0.000e+00 ... 2.100e+02 2.100e+02 1.090e+02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel = sel.fit(train)\n",
    "train_sel = sel.transform(train)\n",
    "test_sel = sel.transform(test)\n",
    "print('训练数据未特征筛选维度', train.shape)\n",
    "print('训练数据特征筛选维度后', train_sel.shape)\n",
    "print(train_sel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Select Accuracy: 0.93 (+/- 0.00)\n",
      "Features Select Accuracy: 0.93 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "feature_selection(train, train_sel, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 单变量特征选择（方法二）\n",
    "通过基于单变量统计检验选择最佳特征。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据未特征筛选维度 (2000, 229)\n",
      "训练数据特征筛选维度后 (2000, 10)\n",
      "No Select Accuracy: 0.93 (+/- 0.00)\n",
      "Features Select Accuracy: 0.93 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "sel = SelectKBest(mutual_info_classif, k=10)\n",
    "sel = sel.fit(train, target)\n",
    "train_sel = sel.transform(train)\n",
    "test_sel = sel.transform(test)\n",
    "print('训练数据未特征筛选维度', train.shape)\n",
    "print('训练数据特征筛选维度后', train_sel.shape)\n",
    "feature_selection(train, train_sel, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 递归功能消除（方法三）\n",
    "选定模型拟合，进行递归拟合，每次把评分低得特征去除，重复上诉循环。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False  True False False False False False  True\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "[226 225 224 223 222 221 220 216 214 213 212 211 209 208 206 204 199 198\n",
      " 190 185 184 183 182 176 175 172 167 166 165 164 163 162 161 160 159 158\n",
      " 157 156 155 154 153 152 151 149 148 147 146 145 143 142 138 137 136 134\n",
      " 132 131 130 129 127 126 125 124 123 120 118 117 116 115 114 109 102 100\n",
      "  98  96  95  93  92  91  90  89  88  87  84  81  66  65  60  51  48  46\n",
      "  36  30  11  13   3   8  10   1   7   2   4   1   5  21   6  12  27   1\n",
      "  33  37  34 169   1 187 191 193 217 219 218 215 195 201 210 207 205 203\n",
      " 202 200 197 196 194 192 189 188 186 179 181 180 178 174  43  49  53  55\n",
      "  57  61  67 150  69 139 144 141 140  71 135 133  73 103 128 105 121 122\n",
      " 119 107 111 113 112 110 108 106 104 101  99  97  75  94  77  79  85  86\n",
      "  83  82  80  78  76  74  72  70  68  63  64  62  59  58  56  54  52  50\n",
      "  47  45  44  42   9  14  15  16  17  18  19  20  22  23  24  25  26  28\n",
      "  29  31  32  35  38  39  40  41 168 170 171 173 177]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0, n_jobs=-1)\n",
    "selector = RFECV(clf, step=1, cv=2)\n",
    "selector = selector.fit(train, target)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 使用模型选择特征（方法四）\n",
    "## 使用LR拟合的参数进行变量选择、\n",
    "（L1或L2范数进行特征选择）\n",
    "LR模型采用拟合参数形式进行变量选择，筛选对回归目标影响大的"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据未特征筛选维度 (2000, 229)\n",
      "训练数据特征筛选维度后 (2000, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalizer = normalizer.fit(train)\n",
    "\n",
    "train_norm = normalizer.transform(train)\n",
    "test_norm = normalizer.transform(test)\n",
    "\n",
    "LR = LogisticRegression(penalty='l2',C=5)\n",
    "LR = LR.fit(train_norm, target)\n",
    "model = SelectFromModel(LR, prefit=True)\n",
    "train_sel = model.transform(train)\n",
    "test_sel = model.transform(test)\n",
    "print('训练数据未特征筛选维度', train.shape)\n",
    "print('训练数据特征筛选维度后', train_sel.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Select Accuracy: 0.93 (+/- 0.00)\n",
      "Features Select Accuracy: 0.93 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "feature_selection(train, train_sel, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 基于树模型特征选择\n",
    "树模型基于分裂评价标准所计算的总的评分作为依据进行相关排序，然后进行特征筛选"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据未特征筛选维度 (2000, 229)\n",
      "训练数据特征筛选维度后 (2000, 68)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(train, target)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "train_sel = model.transform(train)\n",
    "test_sel = model.transform(test)\n",
    "print('训练数据未特征筛选维度', train.shape)\n",
    "print('训练数据特征筛选维度后', train_sel.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "     features_import        features_name\n0           0.085219          merchant_id\n228         0.079468              xgb_clf\n227         0.074071              lgb_clf\n18          0.019578    seller_most_1_cnt\n12          0.018210       time_stamp_std\n20          0.018146     brand_most_1_cnt\n21          0.017891    action_type_1_cnt\n14          0.016927        seller_most_1\n22          0.016911           user_cnt_0\n4           0.016872       seller_nunique\n3           0.016604             user_cnt\n7           0.016288         item_nunique\n15          0.015949           cat_most_1\n8           0.015891   time_stamp_nunique\n1           0.015842            age_range\n16          0.015792         brand_most_1\n23          0.015757           user_cnt_1\n19          0.015585       cat_most_1_cnt\n24          0.015441           user_cnt_2\n25          0.015279           user_cnt_3\n6           0.014900        brand_nunique\n5           0.014223          cat_nunique\n26          0.014095     seller_nunique_0\n112         0.010597             tfidf_85\n87          0.010582             tfidf_60\n2           0.010101               gender\n86          0.008688             tfidf_59\n9           0.008279  action_type_nunique\n49          0.007591             tfidf_22\n28          0.007464              tfidf_1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features_import</th>\n      <th>features_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.085219</td>\n      <td>merchant_id</td>\n    </tr>\n    <tr>\n      <th>228</th>\n      <td>0.079468</td>\n      <td>xgb_clf</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>0.074071</td>\n      <td>lgb_clf</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.019578</td>\n      <td>seller_most_1_cnt</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.018210</td>\n      <td>time_stamp_std</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.018146</td>\n      <td>brand_most_1_cnt</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.017891</td>\n      <td>action_type_1_cnt</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.016927</td>\n      <td>seller_most_1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.016911</td>\n      <td>user_cnt_0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.016872</td>\n      <td>seller_nunique</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016604</td>\n      <td>user_cnt</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.016288</td>\n      <td>item_nunique</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.015949</td>\n      <td>cat_most_1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.015891</td>\n      <td>time_stamp_nunique</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.015842</td>\n      <td>age_range</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.015792</td>\n      <td>brand_most_1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.015757</td>\n      <td>user_cnt_1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.015585</td>\n      <td>cat_most_1_cnt</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.015441</td>\n      <td>user_cnt_2</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.015279</td>\n      <td>user_cnt_3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.014900</td>\n      <td>brand_nunique</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.014223</td>\n      <td>cat_nunique</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.014095</td>\n      <td>seller_nunique_0</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>0.010597</td>\n      <td>tfidf_85</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>0.010582</td>\n      <td>tfidf_60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.010101</td>\n      <td>gender</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>0.008688</td>\n      <td>tfidf_59</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.008279</td>\n      <td>action_type_nunique</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.007591</td>\n      <td>tfidf_22</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.007464</td>\n      <td>tfidf_1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_import = pd.DataFrame()\n",
    "df_features_import['features_import'] = clf.feature_importances_\n",
    "df_features_import['features_name'] = features_columns\n",
    "df_features_import.sort_values(['features_import'],ascending=0).head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Select Accuracy: 0.93 (+/- 0.00)\n",
      "Features Select Accuracy: 0.93 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "feature_selection(train, train_sel, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PCA降维（不是特征选择，是特征提取）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53952808 0.23390601 0.18186468 0.02745562 0.01639371]\n",
      "[5602339.37043684 2428827.83875234 1888442.28695997  285093.00097763\n",
      "  170228.58453105]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "pca.fit(train)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_)\n",
    "print(pca.n_components_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}