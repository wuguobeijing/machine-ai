{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lstm",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple/\n",
      "Requirement already satisfied: spacy in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\python38\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (21.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (4.60.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (0.6.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'D:\\PycharmProjects\\myproject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: setuptools in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (57.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (1.19.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in d:\\python\\python38\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\python\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\python\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\python\\python38\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: colorama in d:\\python\\python38\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\python38\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy -i https://pypi.douban.com/simple/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 696, in urlopen\n",
      "    self._prepare_proxy(conn)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 964, in _prepare_proxy\n",
      "    conn.connect()\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\connection.py\", line 364, in connect\n",
      "    conn = self._connect_tls_proxy(hostname, conn)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\connection.py\", line 501, in _connect_tls_proxy\n",
      "    socket = ssl_wrap_socket(\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 453, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 495, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock)\n",
      "  File \"D:\\Python\\Python38\\lib\\ssl.py\", line 500, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"D:\\Python\\Python38\\lib\\ssl.py\", line 1040, in _create\n",
      "    self.do_handshake()\n",
      "  File \"D:\\Python\\Python38\\lib\\ssl.py\", line 1309, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1125)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\PycharmProjects\\myproject\\venv\\lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"D:\\PycharmProjects\\myproject\\venv\\lib\\site-packages\\spacy\\cli\\_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\click\\core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\click\\core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\click\\core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\click\\core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"D:\\PycharmProjects\\myproject\\venv\\lib\\site-packages\\typer\\main.py\", line 500, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"D:\\PycharmProjects\\myproject\\venv\\lib\\site-packages\\spacy\\cli\\download.py\", line 35, in download_cli\n",
      "    download(model, direct, sdist, *ctx.args)\n",
      "  File \"D:\\PycharmProjects\\myproject\\venv\\lib\\site-packages\\spacy\\cli\\download.py\", line 67, in download\n",
      "    compatibility = get_compatibility()\n",
      "  File \"D:\\PycharmProjects\\myproject\\venv\\lib\\site-packages\\spacy\\cli\\download.py\", line 78, in get_compatibility\n",
      "    r = requests.get(about.__compatibility__)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\requests\\api.py\", line 75, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\requests\\api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Python\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 514, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)')))\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "id": "xazrh9eIcgTO",
    "colab_type": "code",
    "outputId": "eed0e41e-8fad-4940-bab3-8e0a147e0871",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install torch\n",
    "!pip install torchtext\n",
    "\n",
    "\n",
    "# K80 gpu for 12 hours\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext import data, datasets\n",
    "\n",
    "print('GPU:', torch.cuda.is_available())\n",
    "\n",
    "torch.manual_seed(123)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in d:\\python\\python38\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: torch in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from torchtext) (1.10.1)\n",
      "Requirement already satisfied: requests in d:\\python\\python38\\lib\\site-packages (from torchtext) (2.26.0)\n",
      "Requirement already satisfied: six in d:\\python\\python38\\lib\\site-packages (from torchtext) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in d:\\python\\python38\\lib\\site-packages (from torchtext) (0.1.96)\n",
      "Requirement already satisfied: tqdm in d:\\python\\python38\\lib\\site-packages (from torchtext) (4.60.0)\n",
      "Requirement already satisfied: numpy in d:\\python\\python38\\lib\\site-packages (from torchtext) (1.19.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\python38\\lib\\site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\python\\python38\\lib\\site-packages (from requests->torchtext) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\python\\python38\\lib\\site-packages (from requests->torchtext) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\python38\\lib\\site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: typing-extensions in d:\\python\\python38\\lib\\site-packages (from torch->torchtext) (4.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'D:\\PycharmProjects\\myproject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple/\n",
      "Collecting spacy\n",
      "  Downloading https://pypi.doubanio.com/packages/70/32/3a172911ea750748c8625973fd5b3b0f7a291a765d57f83a9ee830f70b07/spacy-3.2.2-cp38-cp38-win_amd64.whl (11.6 MB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading https://pypi.doubanio.com/packages/4f/bd/77f6cb38c291717c5109cc2638086033fd7de4f8aeb0ed95e9ed484efa82/typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (21.2)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading https://pypi.doubanio.com/packages/5a/89/3ddf438f8edcbbbdce93d9edf3e87a8d0680e4ab8d175331e79130878bdd/srsly-2.4.2-cp38-cp38-win_amd64.whl (452 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading https://pypi.doubanio.com/packages/10/7c/041bbbb9d13ce6f45d55ffc49b43572c7c2fbbe2a1405c61251cfcc26210/preshed-3.0.6-cp38-cp38-win_amd64.whl (113 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading https://pypi.doubanio.com/packages/9a/34/44741cf6abdf29b6baee3bc8a0b868213ecb9ed2b9f1c83a276053a32a92/spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading https://pypi.doubanio.com/packages/fe/c3/0d04d248624a181e57c2870127dfa8d371973561caf54333c85e8f9133a2/langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\python38\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading https://pypi.doubanio.com/packages/89/32/f7d47bb433e812c1779c49084dcc3a967dd9e86996bda86dccb6068947fe/thinc-8.0.13-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading https://pypi.doubanio.com/packages/34/40/0d2f208c4a79f06aa530cb6becc67740bb30b0a72d41055a0fa491f3e50f/cymem-2.0.6-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading https://pypi.doubanio.com/packages/11/0f/512c25680bdc80a9a2f53da65f4ade2e9f676489df79589275d37e268909/murmurhash-1.0.6-cp38-cp38-win_amd64.whl (21 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading https://pypi.doubanio.com/packages/2d/d3/b1e56c013113883d81af00c1c916e1be6695fadb6c867314ba0b449e9eba/blis-0.7.5-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading https://pypi.doubanio.com/packages/51/68/6579cb896863715b6a5c63e4983b1c0ab7693685a7c2ded469ef37eb3539/pydantic-1.8.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading https://pypi.doubanio.com/packages/d3/e8/1bc00eeff3faf1c50bde941f88a491a5c1128debb75dd8c913401e71585c/spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading https://pypi.doubanio.com/packages/44/b9/43b8bdc8154f7b895291a3573816216f1c00c23cda7ca2849f3bf9a07e46/pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (1.19.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (4.60.0)\n",
      "Requirement already satisfied: setuptools in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (57.0.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading https://pypi.doubanio.com/packages/1f/8b/273bf7d3863570302401991839e1b2c68ae544cc5b02367f58089db872cb/catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading https://pypi.doubanio.com/packages/da/96/1f8e7a9d5cd48251b84991657ba3aeab9463a9e897ff105f70e103946348/wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in d:\\python\\python38\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\python\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\python\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\python\\python38\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: colorama in d:\\python\\python38\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\python38\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Successfully installed blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 spacy-3.2.2 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0 wasabi-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'D:\\PycharmProjects\\myproject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] 拒绝访问。: 'D:\\\\PycharmProjects\\\\myproject\\\\venv\\\\Lib\\\\site-packages\\\\murmurhash\\\\mrmr.cp38-win_amd64.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 21.1.2; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'D:\\PycharmProjects\\myproject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.2.2-cp38-cp38-win_amd64.whl (11.6 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp38-cp38-win_amd64.whl (452 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-win_amd64.whl (113 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (1.19.4)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\python38\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp38-cp38-win_amd64.whl (21 kB)\n",
      "Requirement already satisfied: setuptools in d:\\pycharmprojects\\myproject\\venv\\lib\\site-packages (from spacy) (57.0.0)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (21.2)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\python\\python38\\lib\\site-packages (from spacy) (4.60.0)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in d:\\python\\python38\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\python\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\python\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\python\\python38\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: colorama in d:\\python\\python38\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\python38\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Collecting en-core-web-sm==3.2.0GPU: False\n",
      "\n",
      "⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='github.com', port=443): Read timed out. (read timeout=15)\")': /explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E30E807730>, 'Connection to github.com timed out. (connect timeout=15)')': /explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E30E807670>, 'Connection to github.com timed out. (connect timeout=15)')': /explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E30E807550>, 'Connection to github.com timed out. (connect timeout=15)')': /explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E30E8176A0>, 'Connection to github.com timed out. (connect timeout=15)')': /explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl\n",
      "ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (Caused by ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E30E817820>, 'Connection to github.com timed out. (connect timeout=15)'))\n",
      "\n",
      "WARNING: You are using pip version 21.1.2; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'D:\\PycharmProjects\\myproject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1e2bb568290>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "id": "sPOkbQz1dfMS",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install SpaCy. See the docs at https://spacy.io for more information.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_708/2366391262.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mTEXT\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mField\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'spacy'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mLABEL\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLabelField\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIMDB\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplits\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mTEXT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mLABEL\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Python\\Python38\\lib\\site-packages\\torchtext\\data\\field.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, tokenizer_language, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001B[0m\n\u001B[0;32m    161\u001B[0m         \u001B[1;31m# in case the tokenizer isn't picklable (e.g. spacy)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenizer_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtokenizer_language\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 163\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_tokenizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtokenizer_language\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minclude_lengths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minclude_lengths\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_first\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch_first\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Python\\Python38\\lib\\site-packages\\torchtext\\data\\utils.py\u001B[0m in \u001B[0;36mget_tokenizer\u001B[1;34m(tokenizer, language)\u001B[0m\n\u001B[0;32m    111\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"spacy\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m             \u001B[1;32mimport\u001B[0m \u001B[0mspacy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m             \u001B[0mspacy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspacy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlanguage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mpartial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_spacy_tokenize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspacy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mspacy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'spacy'"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "LodNOFuEeRuv",
    "colab_type": "code",
    "outputId": "742cd4b9-10a2-4de8-f0e3-2c525b3d5364",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    }
   },
   "cell_type": "code",
   "source": [
    "print('len of train data:', len(train_data))\n",
    "print('len of test data:', len(test_data))"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "len of train data: 25000\n",
      "len of test data: 25000\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "id": "gnQaJuCLee2o",
    "colab_type": "code",
    "outputId": "fb9424f5-2604-4680-c472-2557c0988817",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_data.examples[15].text)\n",
    "print(train_data.examples[15].label)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "['Well', 'when', 'watching', 'this', 'film', 'late', 'one', 'night', 'I', 'was', 'simple', 'amazed', 'by', 'it', \"'s\", 'greatness', '.', 'Fantastic', 'script', ',', 'great', 'acting', ',', 'costumes', 'and', 'special', 'effects', ',', 'and', 'the', 'plot', 'twists', ',', 'wow', '!', '!', 'In', 'fact', 'if', 'you', 'can', 'see', 'the', 'ending', 'coming', 'you', 'should', 'become', 'a', 'writer', 'yourself.<br', '/><br', '/>Great', ',', 'I', 'would', 'recommend', 'this', 'film', 'to', 'anyone', ',', 'especially', 'if', 'I', 'don;t', 'like', 'them', 'much.<br', '/><br', '/>Terrific']\n",
      "pos\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "id": "u3R5sgSme-Tt",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# word2vec, glove\n",
    "TEXT.build_vocab(train_data, max_size=10000, vectors='glove.6B.100d')\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "\n",
    "batchsz = 30\n",
    "device = torch.device('cuda')\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size = batchsz,\n",
    "    device=device\n",
    ")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "PBKKxxFBgRTM",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # [0-10001] => [100]\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # [100] => [256]\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, \n",
    "                           bidirectional=True, dropout=0.5)\n",
    "        # [256*2] => [1]\n",
    "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [seq_len, b] vs [b, 3, 28, 28]\n",
    "        \"\"\"\n",
    "        # [seq, b, 1] => [seq, b, 100]\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        \n",
    "        # output: [seq, b, hid_dim*2]\n",
    "        # hidden/h: [num_layers*2, b, hid_dim]\n",
    "        # cell/c: [num_layers*2, b, hid_di]\n",
    "        output, (hidden, cell) = self.rnn(embedding)\n",
    "        \n",
    "        # [num_layers*2, b, hid_dim] => 2 of [b, hid_dim] => [b, hid_dim*2]\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        \n",
    "        # [b, hid_dim*2] => [b, 1]\n",
    "        hidden = self.dropout(hidden)\n",
    "        out = self.fc(hidden)\n",
    "        \n",
    "        return out"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "cxq70oc9lK-4",
    "colab_type": "code",
    "outputId": "b7bb2f08-0c99-4ac1-9594-e5e98168c19d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    }
   },
   "cell_type": "code",
   "source": [
    "rnn = RNN(len(TEXT.vocab), 100, 256)\n",
    "\n",
    "pretrained_embedding = TEXT.vocab.vectors\n",
    "print('pretrained_embedding:', pretrained_embedding.shape)\n",
    "rnn.embedding.weight.data.copy_(pretrained_embedding)\n",
    "print('embedding layer inited.')\n",
    "\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=1e-3)\n",
    "criteon = nn.BCEWithLogitsLoss().to(device)\n",
    "rnn.to(device)\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "pretrained_embedding: torch.Size([10002, 100])\n",
      "embedding layer inited.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10002, 100)\n",
       "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 7
    }
   ]
  },
  {
   "metadata": {
    "id": "_Rw_PZsZnBuJ",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def binary_acc(preds, y):\n",
    "    \"\"\"\n",
    "    get accuracy\n",
    "    \"\"\"\n",
    "    preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = torch.eq(preds, y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(rnn, iterator, optimizer, criteon):\n",
    "    \n",
    "    avg_acc = []\n",
    "    rnn.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        # [seq, b] => [b, 1] => [b]\n",
    "        pred = rnn(batch.text).squeeze(1)\n",
    "        # \n",
    "        loss = criteon(pred, batch.label)\n",
    "        acc = binary_acc(pred, batch.label).item()\n",
    "        avg_acc.append(acc)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print(i, acc)\n",
    "        \n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    print('avg acc:', avg_acc)\n",
    "    \n",
    "    \n",
    "def eval(rnn, iterator, criteon):\n",
    "    \n",
    "    avg_acc = []\n",
    "    \n",
    "    rnn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "\n",
    "            # [b, 1] => [b]\n",
    "            pred = rnn(batch.text).squeeze(1)\n",
    "\n",
    "            #\n",
    "            loss = criteon(pred, batch.label)\n",
    "\n",
    "            acc = binary_acc(pred, batch.label).item()\n",
    "            avg_acc.append(acc)\n",
    "        \n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    \n",
    "    print('>>test:', avg_acc)\n",
    "        \n",
    "    \n",
    "    "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "lrjzCiiao4Qw",
    "colab_type": "code",
    "outputId": "ddc45f41-982d-4afc-e1c1-36e96a0a6e76",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 14878
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(10):\n",
    "    \n",
    "    eval(rnn, test_iterator, criteon)\n",
    "    train(rnn, train_iterator, optimizer, criteon)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      ">>test: 0.4997602136050769\n",
      "0 0.46666669845581055\n",
      "10 0.40000003576278687\n",
      "20 0.5\n",
      "30 0.5\n",
      "40 0.4333333671092987\n",
      "50 0.5333333611488342\n",
      "60 0.6000000238418579\n",
      "70 0.5666667222976685\n",
      "80 0.40000003576278687\n",
      "90 0.36666667461395264\n",
      "100 0.5333333611488342\n",
      "110 0.6666666865348816\n",
      "120 0.7333333492279053\n",
      "130 0.4333333671092987\n",
      "140 0.6000000238418579\n",
      "150 0.5333333611488342\n",
      "160 0.5\n",
      "170 0.46666669845581055\n",
      "180 0.6333333849906921\n",
      "190 0.6666666865348816\n",
      "200 0.40000003576278687\n",
      "210 0.46666669845581055\n",
      "220 0.5666667222976685\n",
      "230 0.5\n",
      "240 0.7333333492279053\n",
      "250 0.6666666865348816\n",
      "260 0.6333333849906921\n",
      "270 0.6666666865348816\n",
      "280 0.6000000238418579\n",
      "290 0.7666667103767395\n",
      "300 0.6000000238418579\n",
      "310 0.5666667222976685\n",
      "320 0.8333333730697632\n",
      "330 0.6333333849906921\n",
      "340 0.6000000238418579\n",
      "350 0.6333333849906921\n",
      "360 0.6333333849906921\n",
      "370 0.7000000476837158\n",
      "380 0.7333333492279053\n",
      "390 0.6000000238418579\n",
      "400 0.7666667103767395\n",
      "410 0.7333333492279053\n",
      "420 0.8000000715255737\n",
      "430 0.6666666865348816\n",
      "440 0.7666667103767395\n",
      "450 0.5\n",
      "460 0.46666669845581055\n",
      "470 0.7000000476837158\n",
      "480 0.5333333611488342\n",
      "490 0.36666667461395264\n",
      "500 0.7000000476837158\n",
      "510 0.7000000476837158\n",
      "520 0.5333333611488342\n",
      "530 0.6666666865348816\n",
      "540 0.40000003576278687\n",
      "550 0.5333333611488342\n",
      "560 0.5666667222976685\n",
      "570 0.6666666865348816\n",
      "580 0.6000000238418579\n",
      "590 0.5\n",
      "600 0.6000000238418579\n",
      "610 0.5333333611488342\n",
      "620 0.5666667222976685\n",
      "630 0.5666667222976685\n",
      "640 0.6000000238418579\n",
      "650 0.5333333611488342\n",
      "660 0.6666666865348816\n",
      "670 0.6000000238418579\n",
      "680 0.5333333611488342\n",
      "690 0.4333333671092987\n",
      "700 0.46666669845581055\n",
      "710 0.6333333849906921\n",
      "720 0.5333333611488342\n",
      "730 0.6000000238418579\n",
      "740 0.6000000238418579\n",
      "750 0.7333333492279053\n",
      "760 0.40000003576278687\n",
      "770 0.8666667342185974\n",
      "780 0.40000003576278687\n",
      "790 0.5\n",
      "800 0.5333333611488342\n",
      "810 0.5\n",
      "820 0.5666667222976685\n",
      "830 0.6333333849906921\n",
      "avg acc: 0.5920064268852595\n",
      ">>test: 0.5261790834688883\n",
      "0 0.6000000238418579\n",
      "10 0.6333333849906921\n",
      "20 0.7000000476837158\n",
      "30 0.6666666865348816\n",
      "40 0.7000000476837158\n",
      "50 0.7000000476837158\n",
      "60 0.5333333611488342\n",
      "70 0.7000000476837158\n",
      "80 0.7000000476837158\n",
      "90 0.7333333492279053\n",
      "100 0.7666667103767395\n",
      "110 0.7000000476837158\n",
      "120 0.9000000357627869\n",
      "130 0.8000000715255737\n",
      "140 0.8333333730697632\n",
      "150 0.6333333849906921\n",
      "160 0.7000000476837158\n",
      "170 0.9333333969116211\n",
      "180 0.8333333730697632\n",
      "190 0.7666667103767395\n",
      "200 0.8666667342185974\n",
      "210 0.8333333730697632\n",
      "220 0.8666667342185974\n",
      "230 0.8000000715255737\n",
      "240 0.7000000476837158\n",
      "250 0.9000000357627869\n",
      "260 0.8000000715255737\n",
      "270 0.8666667342185974\n",
      "280 0.8333333730697632\n",
      "290 0.8333333730697632\n",
      "300 0.7000000476837158\n",
      "310 0.8666667342185974\n",
      "320 0.8000000715255737\n",
      "330 0.8000000715255737\n",
      "340 0.7666667103767395\n",
      "350 0.9333333969116211\n",
      "360 0.8666667342185974\n",
      "370 0.8000000715255737\n",
      "380 0.8333333730697632\n",
      "390 0.9000000357627869\n",
      "400 0.8666667342185974\n",
      "410 0.7666667103767395\n",
      "420 0.7666667103767395\n",
      "430 0.6666666865348816\n",
      "440 0.9000000357627869\n",
      "450 0.8333333730697632\n",
      "460 0.9000000357627869\n",
      "470 0.8333333730697632\n",
      "480 0.7666667103767395\n",
      "490 0.9000000357627869\n",
      "500 0.9000000357627869\n",
      "510 0.8666667342185974\n",
      "520 0.9000000357627869\n",
      "530 0.8666667342185974\n",
      "540 0.7333333492279053\n",
      "550 0.9000000357627869\n",
      "560 0.9333333969116211\n",
      "570 0.9000000357627869\n",
      "580 0.8000000715255737\n",
      "590 0.8333333730697632\n",
      "600 0.8666667342185974\n",
      "610 0.8333333730697632\n",
      "620 0.8000000715255737\n",
      "630 0.8666667342185974\n",
      "640 0.9666666984558105\n",
      "650 0.8666667342185974\n",
      "660 0.8000000715255737\n",
      "670 0.9000000357627869\n",
      "680 0.8333333730697632\n",
      "690 0.9000000357627869\n",
      "700 0.8333333730697632\n",
      "710 0.8333333730697632\n",
      "720 0.9000000357627869\n",
      "730 0.8333333730697632\n",
      "740 0.8000000715255737\n",
      "750 0.9333333969116211\n",
      "760 0.8000000715255737\n",
      "770 0.8666667342185974\n",
      "780 0.8666667342185974\n",
      "790 0.8000000715255737\n",
      "800 0.8666667342185974\n",
      "810 0.8333333730697632\n",
      "820 0.8000000715255737\n",
      "830 0.9333333969116211\n",
      "avg acc: 0.8121503265641576\n",
      ">>test: 0.8781375387589708\n",
      "0 0.9333333969116211\n",
      "10 0.9000000357627869\n",
      "20 0.9333333969116211\n",
      "30 0.7666667103767395\n",
      "40 0.8666667342185974\n",
      "50 0.9000000357627869\n",
      "60 0.9666666984558105\n",
      "70 0.8333333730697632\n",
      "80 0.8000000715255737\n",
      "90 0.9000000357627869\n",
      "100 0.9666666984558105\n",
      "110 0.8333333730697632\n",
      "120 0.9666666984558105\n",
      "130 0.8666667342185974\n",
      "140 0.8666667342185974\n",
      "150 0.9333333969116211\n",
      "160 0.8000000715255737\n",
      "170 0.7666667103767395\n",
      "180 0.9333333969116211\n",
      "190 0.8000000715255737\n",
      "200 0.9000000357627869\n",
      "210 0.9333333969116211\n",
      "220 0.9000000357627869\n",
      "230 0.7666667103767395\n",
      "240 0.9666666984558105\n",
      "250 0.8666667342185974\n",
      "260 0.9666666984558105\n",
      "270 0.9666666984558105\n",
      "280 0.9000000357627869\n",
      "290 0.8666667342185974\n",
      "300 0.9000000357627869\n",
      "310 0.9333333969116211\n",
      "320 0.9000000357627869\n",
      "330 0.8666667342185974\n",
      "340 0.9333333969116211\n",
      "350 0.9000000357627869\n",
      "360 0.9000000357627869\n",
      "370 0.9333333969116211\n",
      "380 0.9333333969116211\n",
      "390 0.8333333730697632\n",
      "400 0.9333333969116211\n",
      "410 0.9333333969116211\n",
      "420 0.8666667342185974\n",
      "430 0.8333333730697632\n",
      "440 0.9000000357627869\n",
      "450 0.9666666984558105\n",
      "460 0.8333333730697632\n",
      "470 0.9000000357627869\n",
      "480 0.8333333730697632\n",
      "490 0.9000000357627869\n",
      "500 0.8666667342185974\n",
      "510 0.9333333969116211\n",
      "520 0.8666667342185974\n",
      "530 0.8333333730697632\n",
      "540 0.9000000357627869\n",
      "550 0.9666666984558105\n",
      "560 0.9666666984558105\n",
      "570 0.9000000357627869\n",
      "580 0.9333333969116211\n",
      "590 0.8333333730697632\n",
      "600 0.8333333730697632\n",
      "610 0.9666666984558105\n",
      "620 0.9000000357627869\n",
      "630 0.9333333969116211\n",
      "640 0.9666666984558105\n",
      "650 0.9333333969116211\n",
      "660 0.9666666984558105\n",
      "670 0.9333333969116211\n",
      "680 0.8000000715255737\n",
      "690 0.9000000357627869\n",
      "700 0.9000000357627869\n",
      "710 0.8666667342185974\n",
      "720 0.9333333969116211\n",
      "730 0.7666667103767395\n",
      "740 0.9333333969116211\n",
      "750 0.9333333969116211\n",
      "760 0.9666666984558105\n",
      "770 0.8000000715255737\n",
      "780 0.9333333969116211\n",
      "790 0.9000000357627869\n",
      "800 0.9333333969116211\n",
      "810 0.9333333969116211\n",
      "820 0.9333333969116211\n",
      "830 0.8000000715255737\n",
      "avg acc: 0.89184657182339\n",
      ">>test: 0.8595524055780552\n",
      "0 0.9000000357627869\n",
      "10 0.9000000357627869\n",
      "20 0.9333333969116211\n",
      "30 0.9333333969116211\n",
      "40 0.9333333969116211\n",
      "50 0.8666667342185974\n",
      "60 0.8333333730697632\n",
      "70 0.9000000357627869\n",
      "80 0.8666667342185974\n",
      "90 0.8666667342185974\n",
      "100 0.9666666984558105\n",
      "110 0.9666666984558105\n",
      "120 1.0\n",
      "130 0.8666667342185974\n",
      "140 0.9666666984558105\n",
      "150 0.9666666984558105\n",
      "160 0.9000000357627869\n",
      "170 0.9333333969116211\n",
      "180 0.9000000357627869\n",
      "190 0.9000000357627869\n",
      "200 0.8333333730697632\n",
      "210 0.9333333969116211\n",
      "220 0.9333333969116211\n",
      "230 0.9000000357627869\n",
      "240 0.8333333730697632\n",
      "250 0.8666667342185974\n",
      "260 0.9666666984558105\n",
      "270 0.9666666984558105\n",
      "280 0.9333333969116211\n",
      "290 0.9666666984558105\n",
      "300 0.9000000357627869\n",
      "310 0.9333333969116211\n",
      "320 0.9333333969116211\n",
      "330 0.9000000357627869\n",
      "340 0.9000000357627869\n",
      "350 0.9000000357627869\n",
      "360 0.9666666984558105\n",
      "370 0.8666667342185974\n",
      "380 0.9666666984558105\n",
      "390 0.8333333730697632\n",
      "400 0.9333333969116211\n",
      "410 0.9000000357627869\n",
      "420 0.8333333730697632\n",
      "430 0.9000000357627869\n",
      "440 0.9000000357627869\n",
      "450 0.9000000357627869\n",
      "460 0.9333333969116211\n",
      "470 0.8000000715255737\n",
      "480 0.9333333969116211\n",
      "490 0.9333333969116211\n",
      "500 0.9666666984558105\n",
      "510 0.9333333969116211\n",
      "520 0.9333333969116211\n",
      "530 0.8666667342185974\n",
      "540 0.9000000357627869\n",
      "550 0.9333333969116211\n",
      "560 0.9000000357627869\n",
      "570 0.9000000357627869\n",
      "580 0.9333333969116211\n",
      "590 0.8000000715255737\n",
      "600 0.8666667342185974\n",
      "610 0.9666666984558105\n",
      "620 0.9333333969116211\n",
      "630 0.9000000357627869\n",
      "640 0.9333333969116211\n",
      "650 0.9000000357627869\n",
      "660 0.9333333969116211\n",
      "670 0.8000000715255737\n",
      "680 0.9000000357627869\n",
      "690 0.9000000357627869\n",
      "700 0.9000000357627869\n",
      "710 0.8000000715255737\n",
      "720 0.8666667342185974\n",
      "730 0.9666666984558105\n",
      "740 0.9666666984558105\n",
      "750 0.9666666984558105\n",
      "760 0.9333333969116211\n",
      "770 0.9000000357627869\n",
      "780 0.8666667342185974\n",
      "790 0.8666667342185974\n",
      "800 0.9333333969116211\n",
      "810 0.9333333969116211\n",
      "820 0.9333333969116211\n",
      "830 0.8666667342185974\n",
      "avg acc: 0.9173062009205349\n",
      ">>test: 0.8850919751526355\n",
      "0 0.8666667342185974\n",
      "10 0.9000000357627869\n",
      "20 0.8666667342185974\n",
      "30 0.8666667342185974\n",
      "40 0.9666666984558105\n",
      "50 0.9333333969116211\n",
      "60 0.9000000357627869\n",
      "70 0.9666666984558105\n",
      "80 1.0\n",
      "90 0.9333333969116211\n",
      "100 0.8666667342185974\n",
      "110 0.8333333730697632\n",
      "120 0.9000000357627869\n",
      "130 0.9666666984558105\n",
      "140 1.0\n",
      "150 1.0\n",
      "160 0.9333333969116211\n",
      "170 0.7333333492279053\n",
      "180 0.9000000357627869\n",
      "190 0.9000000357627869\n",
      "200 1.0\n",
      "210 0.9666666984558105\n",
      "220 0.9000000357627869\n",
      "230 0.8666667342185974\n",
      "240 0.9333333969116211\n",
      "250 0.9333333969116211\n",
      "260 0.9000000357627869\n",
      "270 0.9666666984558105\n",
      "280 0.9333333969116211\n",
      "290 0.9333333969116211\n",
      "300 0.9333333969116211\n",
      "310 0.9333333969116211\n",
      "320 0.8333333730697632\n",
      "330 0.8666667342185974\n",
      "340 0.9000000357627869\n",
      "350 0.9666666984558105\n",
      "360 0.8000000715255737\n",
      "370 0.9666666984558105\n",
      "380 0.9666666984558105\n",
      "390 0.9333333969116211\n",
      "400 1.0\n",
      "410 0.9666666984558105\n",
      "420 1.0\n",
      "430 0.9666666984558105\n",
      "440 1.0\n",
      "450 0.8333333730697632\n",
      "460 0.8666667342185974\n",
      "470 0.9666666984558105\n",
      "480 0.8666667342185974\n",
      "490 0.9000000357627869\n",
      "500 0.9666666984558105\n",
      "510 0.9333333969116211\n",
      "520 0.9666666984558105\n",
      "530 0.9000000357627869\n",
      "540 0.9666666984558105\n",
      "550 0.9333333969116211\n",
      "560 0.9666666984558105\n",
      "570 0.9333333969116211\n",
      "580 0.9666666984558105\n",
      "590 1.0\n",
      "600 1.0\n",
      "610 0.9000000357627869\n",
      "620 0.9333333969116211\n",
      "630 0.8666667342185974\n",
      "640 0.9666666984558105\n",
      "650 0.9333333969116211\n",
      "660 1.0\n",
      "670 0.9000000357627869\n",
      "680 0.9666666984558105\n",
      "690 0.8666667342185974\n",
      "700 0.9333333969116211\n",
      "710 0.8666667342185974\n",
      "720 1.0\n",
      "730 0.9333333969116211\n",
      "740 0.9666666984558105\n",
      "750 0.9666666984558105\n",
      "760 0.9666666984558105\n",
      "770 1.0\n",
      "780 1.0\n",
      "790 0.9000000357627869\n",
      "800 0.9333333969116211\n",
      "810 0.9333333969116211\n",
      "820 0.9666666984558105\n",
      "830 0.9333333969116211\n",
      "avg acc: 0.930255836863026\n",
      ">>test: 0.8738209919320593\n",
      "0 0.9333333969116211\n",
      "10 1.0\n",
      "20 0.9000000357627869\n",
      "30 0.9666666984558105\n",
      "40 0.8000000715255737\n",
      "50 0.9666666984558105\n",
      "60 0.9666666984558105\n",
      "70 1.0\n",
      "80 0.9666666984558105\n",
      "90 0.9666666984558105\n",
      "100 0.9000000357627869\n",
      "110 0.9000000357627869\n",
      "120 0.9666666984558105\n",
      "130 0.9000000357627869\n",
      "140 0.9333333969116211\n",
      "150 0.9000000357627869\n",
      "160 0.9666666984558105\n",
      "170 1.0\n",
      "180 0.9666666984558105\n",
      "190 1.0\n",
      "200 0.9666666984558105\n",
      "210 0.9666666984558105\n",
      "220 0.9000000357627869\n",
      "230 0.9333333969116211\n",
      "240 0.9000000357627869\n",
      "250 0.9666666984558105\n",
      "260 0.9666666984558105\n",
      "270 0.9666666984558105\n",
      "280 0.9333333969116211\n",
      "290 0.9333333969116211\n",
      "300 0.9333333969116211\n",
      "310 0.9666666984558105\n",
      "320 0.9333333969116211\n",
      "330 0.9666666984558105\n",
      "340 0.9666666984558105\n",
      "350 0.8666667342185974\n",
      "360 0.9333333969116211\n",
      "370 0.9666666984558105\n",
      "380 0.8333333730697632\n",
      "390 0.9333333969116211\n",
      "400 0.8666667342185974\n",
      "410 0.9666666984558105\n",
      "420 0.9333333969116211\n",
      "430 0.9666666984558105\n",
      "440 0.9000000357627869\n",
      "450 0.9000000357627869\n",
      "460 0.9333333969116211\n",
      "470 0.9333333969116211\n",
      "480 0.9666666984558105\n",
      "490 1.0\n",
      "500 0.9333333969116211\n",
      "510 0.9666666984558105\n",
      "520 0.9333333969116211\n",
      "530 0.9666666984558105\n",
      "540 0.8333333730697632\n",
      "550 0.9000000357627869\n",
      "560 0.9666666984558105\n",
      "570 0.9000000357627869\n",
      "580 0.9666666984558105\n",
      "590 1.0\n",
      "600 0.9000000357627869\n",
      "610 0.9333333969116211\n",
      "620 1.0\n",
      "630 0.9333333969116211\n",
      "640 0.9666666984558105\n",
      "650 0.9666666984558105\n",
      "660 0.9666666984558105\n",
      "670 0.9333333969116211\n",
      "680 0.8666667342185974\n",
      "690 0.9333333969116211\n",
      "700 0.9666666984558105\n",
      "710 0.9666666984558105\n",
      "720 0.9333333969116211\n",
      "730 0.9000000357627869\n",
      "740 0.9666666984558105\n",
      "750 1.0\n",
      "760 0.8666667342185974\n",
      "770 1.0\n",
      "780 0.8666667342185974\n",
      "790 0.9333333969116211\n",
      "800 0.9333333969116211\n",
      "810 0.9666666984558105\n",
      "820 1.0\n",
      "830 0.9333333969116211\n",
      "avg acc: 0.9423661449258562\n",
      ">>test: 0.8875300253180863\n",
      "0 0.9666666984558105\n",
      "10 1.0\n",
      "20 0.9666666984558105\n",
      "30 0.9666666984558105\n",
      "40 0.9333333969116211\n",
      "50 0.9333333969116211\n",
      "60 0.9333333969116211\n",
      "70 0.9000000357627869\n",
      "80 0.9333333969116211\n",
      "90 0.9333333969116211\n",
      "100 1.0\n",
      "110 0.9666666984558105\n",
      "120 0.8666667342185974\n",
      "130 0.9666666984558105\n",
      "140 0.9000000357627869\n",
      "150 0.9333333969116211\n",
      "160 0.9333333969116211\n",
      "170 1.0\n",
      "180 0.9666666984558105\n",
      "190 0.9333333969116211\n",
      "200 0.9000000357627869\n",
      "210 0.9666666984558105\n",
      "220 1.0\n",
      "230 0.9666666984558105\n",
      "240 0.9333333969116211\n",
      "250 0.9666666984558105\n",
      "260 0.9000000357627869\n",
      "270 0.9666666984558105\n",
      "280 0.9333333969116211\n",
      "290 0.9333333969116211\n",
      "300 0.9666666984558105\n",
      "310 1.0\n",
      "320 0.9666666984558105\n",
      "330 0.9666666984558105\n",
      "340 1.0\n",
      "350 0.9666666984558105\n",
      "360 1.0\n",
      "370 0.9666666984558105\n",
      "380 1.0\n",
      "390 0.9666666984558105\n",
      "400 0.9333333969116211\n",
      "410 1.0\n",
      "420 0.9666666984558105\n",
      "430 0.9333333969116211\n",
      "440 0.8666667342185974\n",
      "450 0.8666667342185974\n",
      "460 0.9666666984558105\n",
      "470 0.9666666984558105\n",
      "480 0.9333333969116211\n",
      "490 1.0\n",
      "500 0.9666666984558105\n",
      "510 0.9666666984558105\n",
      "520 1.0\n",
      "530 0.9666666984558105\n",
      "540 1.0\n",
      "550 0.9333333969116211\n",
      "560 0.9333333969116211\n",
      "570 0.9333333969116211\n",
      "580 0.9000000357627869\n",
      "590 1.0\n",
      "600 0.9333333969116211\n",
      "610 1.0\n",
      "620 1.0\n",
      "630 0.9000000357627869\n",
      "640 1.0\n",
      "650 0.9333333969116211\n",
      "660 0.9333333969116211\n",
      "670 0.9333333969116211\n",
      "680 0.8666667342185974\n",
      "690 0.9000000357627869\n",
      "700 0.9333333969116211\n",
      "710 0.7000000476837158\n",
      "720 0.9666666984558105\n",
      "730 0.9333333969116211\n",
      "740 1.0\n",
      "750 1.0\n",
      "760 1.0\n",
      "770 1.0\n",
      "780 0.9666666984558105\n",
      "790 1.0\n",
      "800 0.9333333969116211\n",
      "810 0.8000000715255737\n",
      "820 0.9666666984558105\n",
      "830 0.9666666984558105\n",
      "avg acc: 0.9476419227014629\n",
      ">>test: 0.8856914953933918\n",
      "0 0.9000000357627869\n",
      "10 0.9333333969116211\n",
      "20 0.9333333969116211\n",
      "30 0.9333333969116211\n",
      "40 0.9666666984558105\n",
      "50 0.9666666984558105\n",
      "60 1.0\n",
      "70 0.9666666984558105\n",
      "80 1.0\n",
      "90 1.0\n",
      "100 0.9333333969116211\n",
      "110 1.0\n",
      "120 1.0\n",
      "130 0.9666666984558105\n",
      "140 0.9333333969116211\n",
      "150 0.9333333969116211\n",
      "160 0.9333333969116211\n",
      "170 1.0\n",
      "180 1.0\n",
      "190 0.9666666984558105\n",
      "200 0.9666666984558105\n",
      "210 0.9333333969116211\n",
      "220 0.9666666984558105\n",
      "230 0.9666666984558105\n",
      "240 1.0\n",
      "250 0.8666667342185974\n",
      "260 0.9666666984558105\n",
      "270 0.9666666984558105\n",
      "280 0.9333333969116211\n",
      "290 0.9666666984558105\n",
      "300 0.9333333969116211\n",
      "310 1.0\n",
      "320 0.9666666984558105\n",
      "330 0.9333333969116211\n",
      "340 0.9333333969116211\n",
      "350 0.9333333969116211\n",
      "360 0.9333333969116211\n",
      "370 0.9000000357627869\n",
      "380 0.9666666984558105\n",
      "390 0.9333333969116211\n",
      "400 1.0\n",
      "410 0.9666666984558105\n",
      "420 1.0\n",
      "430 0.9666666984558105\n",
      "440 1.0\n",
      "450 0.8333333730697632\n",
      "460 0.9333333969116211\n",
      "470 0.9666666984558105\n",
      "480 0.9666666984558105\n",
      "490 0.8666667342185974\n",
      "500 1.0\n",
      "510 0.9000000357627869\n",
      "520 0.9666666984558105\n",
      "530 0.9000000357627869\n",
      "540 0.9333333969116211\n",
      "550 1.0\n",
      "560 0.9333333969116211\n",
      "570 0.9666666984558105\n",
      "580 0.9333333969116211\n",
      "590 0.9666666984558105\n",
      "600 0.9333333969116211\n",
      "610 0.9666666984558105\n",
      "620 1.0\n",
      "630 1.0\n",
      "640 0.9666666984558105\n",
      "650 0.9666666984558105\n",
      "660 0.9666666984558105\n",
      "670 0.9666666984558105\n",
      "680 1.0\n",
      "690 0.9333333969116211\n",
      "700 0.9333333969116211\n",
      "710 0.9666666984558105\n",
      "720 0.9000000357627869\n",
      "730 0.9666666984558105\n",
      "740 1.0\n",
      "750 1.0\n",
      "760 1.0\n",
      "770 0.9666666984558105\n",
      "780 0.9666666984558105\n",
      "790 1.0\n",
      "800 0.9666666984558105\n",
      "810 0.9333333969116211\n",
      "820 0.9666666984558105\n",
      "830 0.9000000357627869\n",
      "avg acc: 0.955435684401926\n",
      ">>test: 0.8800959719313706\n",
      "0 0.9666666984558105\n",
      "10 0.9000000357627869\n",
      "20 1.0\n",
      "30 0.9666666984558105\n",
      "40 1.0\n",
      "50 0.9333333969116211\n",
      "60 0.8666667342185974\n",
      "70 1.0\n",
      "80 0.9666666984558105\n",
      "90 0.9666666984558105\n",
      "100 1.0\n",
      "110 0.9666666984558105\n",
      "120 1.0\n",
      "130 1.0\n",
      "140 0.9333333969116211\n",
      "150 0.9666666984558105\n",
      "160 0.9333333969116211\n",
      "170 0.9666666984558105\n",
      "180 0.9666666984558105\n",
      "190 1.0\n",
      "200 1.0\n",
      "210 0.9333333969116211\n",
      "220 1.0\n",
      "230 1.0\n",
      "240 1.0\n",
      "250 0.9333333969116211\n",
      "260 1.0\n",
      "270 0.9666666984558105\n",
      "280 1.0\n",
      "290 0.9666666984558105\n",
      "300 1.0\n",
      "310 0.9666666984558105\n",
      "320 1.0\n",
      "330 1.0\n",
      "340 0.9333333969116211\n",
      "350 0.9333333969116211\n",
      "360 1.0\n",
      "370 0.9333333969116211\n",
      "380 1.0\n",
      "390 0.9666666984558105\n",
      "400 0.8666667342185974\n",
      "410 1.0\n",
      "420 0.9666666984558105\n",
      "430 0.9666666984558105\n",
      "440 1.0\n",
      "450 0.9000000357627869\n",
      "460 0.9333333969116211\n",
      "470 1.0\n",
      "480 0.9333333969116211\n",
      "490 1.0\n",
      "500 0.9666666984558105\n",
      "510 0.9333333969116211\n",
      "520 0.9333333969116211\n",
      "530 1.0\n",
      "540 0.9666666984558105\n",
      "550 0.9666666984558105\n",
      "560 0.9666666984558105\n",
      "570 1.0\n",
      "580 1.0\n",
      "590 0.9333333969116211\n",
      "600 0.9666666984558105\n",
      "610 0.9666666984558105\n",
      "620 0.9333333969116211\n",
      "630 0.9000000357627869\n",
      "640 0.9000000357627869\n",
      "650 0.9666666984558105\n",
      "660 0.9666666984558105\n",
      "670 0.9666666984558105\n",
      "680 0.9666666984558105\n",
      "690 0.9666666984558105\n",
      "700 0.9000000357627869\n",
      "710 0.9000000357627869\n",
      "720 1.0\n",
      "730 0.9000000357627869\n",
      "740 0.9333333969116211\n",
      "750 0.9333333969116211\n",
      "760 0.9333333969116211\n",
      "770 1.0\n",
      "780 0.8666667342185974\n",
      "790 1.0\n",
      "800 0.9666666984558105\n",
      "810 1.0\n",
      "820 0.9000000357627869\n",
      "830 0.9666666984558105\n",
      "avg acc: 0.9621503096547344\n",
      ">>test: 0.8820943735200438\n",
      "0 1.0\n",
      "10 1.0\n",
      "20 1.0\n",
      "30 1.0\n",
      "40 1.0\n",
      "50 1.0\n",
      "60 1.0\n",
      "70 0.9666666984558105\n",
      "80 0.9333333969116211\n",
      "90 0.9666666984558105\n",
      "100 0.9666666984558105\n",
      "110 0.9666666984558105\n",
      "120 0.9333333969116211\n",
      "130 1.0\n",
      "140 1.0\n",
      "150 0.9666666984558105\n",
      "160 0.9666666984558105\n",
      "170 1.0\n",
      "180 1.0\n",
      "190 0.9333333969116211\n",
      "200 1.0\n",
      "210 1.0\n",
      "220 0.9666666984558105\n",
      "230 1.0\n",
      "240 0.9666666984558105\n",
      "250 1.0\n",
      "260 0.9333333969116211\n",
      "270 0.9666666984558105\n",
      "280 1.0\n",
      "290 1.0\n",
      "300 0.9333333969116211\n",
      "310 0.9666666984558105\n",
      "320 1.0\n",
      "330 1.0\n",
      "340 1.0\n",
      "350 0.9333333969116211\n",
      "360 0.9333333969116211\n",
      "370 0.9666666984558105\n",
      "380 1.0\n",
      "390 1.0\n",
      "400 0.9666666984558105\n",
      "410 0.9666666984558105\n",
      "420 1.0\n",
      "430 0.9666666984558105\n",
      "440 1.0\n",
      "450 0.9333333969116211\n",
      "460 0.9333333969116211\n",
      "470 0.9666666984558105\n",
      "480 1.0\n",
      "490 0.9666666984558105\n",
      "500 0.9666666984558105\n",
      "510 1.0\n",
      "520 0.9666666984558105\n",
      "530 0.9666666984558105\n",
      "540 0.9333333969116211\n",
      "550 0.9666666984558105\n",
      "560 0.9666666984558105\n",
      "570 0.9666666984558105\n",
      "580 0.9666666984558105\n",
      "590 0.9333333969116211\n",
      "600 0.9666666984558105\n",
      "610 0.9666666984558105\n",
      "620 1.0\n",
      "630 1.0\n",
      "640 1.0\n",
      "650 1.0\n",
      "660 0.9666666984558105\n",
      "670 0.9666666984558105\n",
      "680 0.9666666984558105\n",
      "690 0.9333333969116211\n",
      "700 0.9333333969116211\n",
      "710 0.9666666984558105\n",
      "720 0.9333333969116211\n",
      "730 0.9666666984558105\n",
      "740 0.9333333969116211\n",
      "750 0.9666666984558105\n",
      "760 1.0\n",
      "770 0.9333333969116211\n",
      "780 0.9333333969116211\n",
      "790 0.9666666984558105\n",
      "800 1.0\n",
      "810 0.9666666984558105\n",
      "820 0.9666666984558105\n",
      "830 0.9666666984558105\n",
      "avg acc: 0.9673461499545786\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}