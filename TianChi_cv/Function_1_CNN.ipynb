{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 数据扩增\n",
    "在赛题中我们需要对的图像进行字符识别，因此需要我们完成的数据的读取操作，同时也需要完成数据扩增（Data Augmentation）操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "在深度学习中数据扩增方法非常重要\n",
    "数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "从颜色空间、尺度空间到样本空间，同时根据不同任务数据扩增都有相应的区别。\n",
    "对于图像分类，数据扩增一般不会改变标签；对于物体检测，数据扩增会改变物体坐标位置；对于图像分割，数据扩增会改变像素标签。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 常见的数据扩增方法\n",
    "在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。\n",
    "\n",
    "以torchvision为例，常见的数据扩增方法包括：\n",
    "\n",
    "transforms.CenterCrop 对图片中心进行裁剪\n",
    "transforms.ColorJitter 对图像颜色的对比度、饱和度和零度进行变换\n",
    "transforms.FiveCrop 对图像四个角和中心进行裁剪得到五分图像\n",
    "transforms.Grayscale 对图像进行灰度变换\n",
    "transforms.Pad 使用固定值进行像素填充\n",
    "transforms.RandomAffine 随机仿射变换\n",
    "transforms.RandomCrop 随机区域裁剪\n",
    "transforms.RandomHorizontalFlip 随机水平翻转\n",
    "transforms.RandomRotation 随机旋转\n",
    "transforms.RandomVerticalFlip 随机垂直翻转\n",
    "赛题任务是需要对图像中的字符进行识别，因此对于字符图片并不能进行翻转操作。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 常用的数据扩增库\n",
    "torchvision\n",
    "https://github.com/pytorch/vision\n",
    "pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；\n",
    "\n",
    "imgaug\n",
    "https://github.com/aleju/imgaug\n",
    "imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；\n",
    "\n",
    "albumentations\n",
    "https://albumentations.readthedocs.io\n",
    "是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 用Pytorch读取赛题数据\n",
    "在Pytorch中数据是通过Dataset进行封装，并通过DataLoder进行并行读取。所以我们只需要重载一下数据读取的逻辑就可以完成数据的读取。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wuguo\\pycharmprojects\\machine-ai\\venv\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\wuguo\\PycharmProjects\\machine-ai\\venv\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 原始SVHN中类别10为数字0\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        # print(lbl)\n",
    "        lbl = list(lbl)  + (6 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:6]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "train_path = glob.glob('./input/train/*.png')\n",
    "train_path.sort()\n",
    "# print(train_path)\n",
    "train_json = json.load(open('./input/train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "# 验证集\n",
    "\n",
    "val_path = glob.glob('./input/val/*.png')\n",
    "val_path.sort()\n",
    "# print(train_path)\n",
    "val_json = json.load(open('./input/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果图中数字为1，9的话，通过以上方法在遍历图片时可以得到[1,9,10,10,10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_data = SVHNDataset(train_path, train_label,\n",
    "          transforms.Compose([\n",
    "              # 缩放到固定尺寸\n",
    "              transforms.Resize((64, 128)),\n",
    "\n",
    "              # 随机颜色变换\n",
    "              transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "\n",
    "              # 加入随机旋转\n",
    "              transforms.RandomRotation(5),\n",
    "\n",
    "              # 将图片转换为pytorch 的tesntor\n",
    "              transforms.ToTensor(),\n",
    "\n",
    "              # 对图像像素进行归一化\n",
    "              transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ]))\n",
    "val_data = SVHNDataset(val_path, val_label,\n",
    "          transforms.Compose([\n",
    "              # 缩放到固定尺寸\n",
    "              transforms.Resize((64, 128)),\n",
    "\n",
    "              # 随机颜色变换\n",
    "              transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "\n",
    "              # 加入随机旋转\n",
    "              transforms.RandomRotation(5),\n",
    "\n",
    "              # 将图片转换为pytorch 的tesntor\n",
    "              transforms.ToTensor(),\n",
    "\n",
    "              # 对图像像素进行归一化\n",
    "              transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ]))\n",
    "#使用DataLoader封装数据\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "       train_data,\n",
    "    batch_size=10, # 每批样本个数\n",
    "    shuffle=False, # 是否打乱顺序\n",
    "    # num_workers=10, # 读取的线程个数\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "       val_data,\n",
    "    batch_size=10, # 每批样本个数\n",
    "    shuffle=False, # 是否打乱顺序\n",
    "    # num_workers=10, # 读取的线程个数\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([10, 3, 64, 128]) torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx,(pic,lable) in enumerate(train_loader):\n",
    "    print(batch_idx)\n",
    "    print(pic.shape,lable.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import torch.nn as nn\n",
    "from visdom import Visdom\n",
    "# 定义模型\n",
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "        # CNN提取特征模块\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        #\n",
    "        self.fc1 = nn.Linear(32*3*7, 11)\n",
    "        self.fc2 = nn.Linear(32*3*7, 11)\n",
    "        self.fc3 = nn.Linear(32*3*7, 11)\n",
    "        self.fc4 = nn.Linear(32*3*7, 11)\n",
    "        self.fc5 = nn.Linear(32*3*7, 11)\n",
    "        self.fc6 = nn.Linear(32*3*7, 11)\n",
    "\n",
    "    def forward(self, img):\n",
    "        feat = self.cnn(img)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        c6 = self.fc6(feat)\n",
    "        return c1, c2, c3, c4, c5, c6\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model = SVHN_Model1().to(device)\n",
    "# net = MLP().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, global_step):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:\n",
    "        pic = data[0].to(device)\n",
    "        c0, c1, c2, c3, c4, c5 = model(pic)\n",
    "        lables = data[1].long().to(device)\n",
    "        loss = criterion(c0, lables[:, 0]) + \\\n",
    "                criterion(c1, lables[:, 1]) + \\\n",
    "                criterion(c2, lables[:, 2]) + \\\n",
    "                criterion(c3, lables[:, 3]) + \\\n",
    "                criterion(c4, lables[:, 4]) + \\\n",
    "                criterion(c5, lables[:, 5])\n",
    "        loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        viz.line([loss.item()], [global_step], win='train', update='append')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            pic = data[0].to(device)\n",
    "            c0, c1, c2, c3, c4, c5 = model(pic)\n",
    "            lables = data[1].long().to(device)\n",
    "            loss = criterion(c0, lables[:, 0]) + \\\n",
    "                    criterion(c1, lables[:, 1]) + \\\n",
    "                    criterion(c2, lables[:, 2]) + \\\n",
    "                    criterion(c3, lables[:, 3]) + \\\n",
    "                    criterion(c4, lables[:, 4]) + \\\n",
    "                    criterion(c5, lables[:, 5])\n",
    "            loss /= 6\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0.9168664121627808\n",
      "Epoch:  1\n",
      "0.8846571270823479\n",
      "Epoch:  2\n",
      "0.894153025329113\n",
      "Epoch:  3\n",
      "0.8937509346604348\n",
      "Epoch:  4\n",
      "0.8844235015511512\n",
      "Epoch:  5\n",
      "0.8827899129986763\n",
      "Epoch:  6\n",
      "0.8681970564723015\n",
      "Epoch:  7\n",
      "0.8955453754663467\n",
      "Epoch:  8\n",
      "0.8790286925435066\n",
      "Epoch:  9\n",
      "0.886190665781498\n"
     ]
    }
   ],
   "source": [
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.005)\n",
    "# 绘图工具\n",
    "viz = Visdom()\n",
    "global_step = 0\n",
    "viz.line([0.], [0.], win='train',opts=dict(title='train loss.',\n",
    "                                                   legend=['loss']))\n",
    "loss_plot = []\n",
    "# c0_plot = []\n",
    "# 迭代10个Epoch\n",
    "best_loss = 1000.0\n",
    "for epoch in range(10):\n",
    "    print('Epoch: ', epoch)\n",
    "\n",
    "    train(train_loader, model, criterion, optimizer, epoch, global_step)\n",
    "    val_loss = validate(val_loader, model, criterion)\n",
    "    print(val_loss)\n",
    "    # 记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), './model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#加载模型的方法\n",
    "# model.load_state_dict(torch.load(' model.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}