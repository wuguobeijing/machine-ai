{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "30000 30000\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, glob, shutil, json\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from visdom import Visdom\n",
    "\n",
    "%pylab inline\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 原始SVHN中类别10为数字0\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        # print(lbl)\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "train_path = glob.glob('./input/train/*.png')\n",
    "train_path.sort()\n",
    "# print(train_path)\n",
    "train_json = json.load(open('./input/train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "# 验证集\n",
    "\n",
    "val_path = glob.glob('./input/val/*.png')\n",
    "val_path.sort()\n",
    "# print(train_path)\n",
    "val_json = json.load(open('./input/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "\n",
    "train_data = SVHNDataset(train_path, train_label,\n",
    "          transforms.Compose([\n",
    "              # 缩放到固定尺寸\n",
    "              transforms.Resize((64, 128)),\n",
    "\n",
    "              # 随机颜色变换\n",
    "              transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "\n",
    "              # 加入随机旋转\n",
    "              transforms.RandomRotation(15),\n",
    "              # 加入随机裁剪\n",
    "              transforms.RandomCrop((60,120)),\n",
    "              # 将图片转换为pytorch 的tesntor\n",
    "              transforms.ToTensor(),\n",
    "\n",
    "              # 对图像像素进行归一化\n",
    "              transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ]))\n",
    "val_data = SVHNDataset(val_path, val_label,\n",
    "          transforms.Compose([\n",
    "              # 缩放到固定尺寸\n",
    "              transforms.Resize((64, 128)),\n",
    "\n",
    "              # 随机颜色变换\n",
    "              transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "              # 加入随机裁剪\n",
    "              transforms.RandomCrop((60,120)),\n",
    "              # 加入随机旋转\n",
    "              transforms.RandomRotation(15),\n",
    "\n",
    "              # 将图片转换为pytorch 的tesntor\n",
    "              transforms.ToTensor(),\n",
    "\n",
    "              # 对图像像素进行归一化\n",
    "              transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ]))\n",
    "#使用DataLoader封装数据\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "       train_data,\n",
    "    batch_size=10, # 每批样本个数\n",
    "    shuffle=False, # 是否打乱顺序\n",
    "    # num_workers=10, # 读取的线程个数\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "       val_data,\n",
    "    batch_size=10, # 每批样本个数\n",
    "    shuffle=False, # 是否打乱顺序\n",
    "    # num_workers=10, # 读取的线程个数\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义分类模型\n",
    "这里使用ResNet50的模型进行特征提取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "\n",
    "        model_conv = models.resnet50(pretrained=True)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])# 去除最后一个fc layer\n",
    "        self.cnn = model_conv\n",
    "        self.fc11 = nn.Linear(2048, 128)\n",
    "        self.fc21 = nn.Linear(2048, 128)\n",
    "        self.fc31 = nn.Linear(2048, 128)\n",
    "        self.fc41 = nn.Linear(2048, 128)\n",
    "        self.fc51 = nn.Linear(2048, 128)\n",
    "        # self.fc6 = nn.Linear(512, 11)\n",
    "        self.dropout_1 = nn.Dropout(0.3)\n",
    "        self.dropout_2 = nn.Dropout(0.3)\n",
    "        self.dropout_3 = nn.Dropout(0.3)\n",
    "        self.dropout_4 = nn.Dropout(0.3)\n",
    "        self.dropout_5 = nn.Dropout(0.3)\n",
    "        self.fc12 = nn.Linear(128,11)\n",
    "        self.fc22 = nn.Linear(128,11)\n",
    "        self.fc32 = nn.Linear(128,11)\n",
    "        self.fc42 = nn.Linear(128,11)\n",
    "        self.fc52 = nn.Linear(128,11)\n",
    "    def forward(self, img):\n",
    "        feat = self.cnn(img)\n",
    "        # print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc11(feat)\n",
    "        c2 = self.fc21(feat)\n",
    "        c3 = self.fc31(feat)\n",
    "        c4 = self.fc41(feat)\n",
    "        c5 = self.fc51(feat)\n",
    "        c1 = self.dropout_1(c1)\n",
    "        c2 = self.dropout_2(c2)\n",
    "        c3 = self.dropout_3(c3)\n",
    "        c4 = self.dropout_4(c4)\n",
    "        c5 = self.dropout_5(c5)\n",
    "        c1 = self.fc12(c1)\n",
    "        c2 = self.fc22(c2)\n",
    "        c3 = self.fc32(c3)\n",
    "        c4 = self.fc42(c4)\n",
    "        c5 = self.fc52(c5)\n",
    "        # c6 = self.fc6(feat)\n",
    "        return c1, c2, c3, c4, c5# , c6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "def train(train_loader, model, criterion, optimizer, epoch, global_step):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    for data in train_loader:\n",
    "        if use_cuda:\n",
    "            pic = data[0].cuda()\n",
    "            lables = data[1].long().cuda()\n",
    "        else:\n",
    "            pic = data[0]\n",
    "            lables = data[1].long()\n",
    "        c0, c1, c2, c3, c4 = model(pic)\n",
    "        loss = criterion(c0, lables[:, 0]) + \\\n",
    "                criterion(c1, lables[:, 1]) + \\\n",
    "                criterion(c2, lables[:, 2]) + \\\n",
    "                criterion(c3, lables[:, 3]) + \\\n",
    "                criterion(c4, lables[:, 4]) # + \\\n",
    "                # criterion(c5, lables[:, 5])\n",
    "        loss /= 5\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        if global_step%100 ==0:\n",
    "            viz.line([loss.item()], [global_step/100], win='train', update='append')\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion,global_step_val):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            if use_cuda:\n",
    "                pic = data[0].cuda()\n",
    "                lables = data[1].long().cuda()\n",
    "            else:\n",
    "                pic = data[0]\n",
    "                lables = data[1].long()\n",
    "            c0, c1, c2, c3, c4 = model(pic)\n",
    "            loss = criterion(c0, lables[:, 0]) + \\\n",
    "                    criterion(c1, lables[:, 1]) + \\\n",
    "                    criterion(c2, lables[:, 2]) + \\\n",
    "                    criterion(c3, lables[:, 3]) + \\\n",
    "                    criterion(c4, lables[:, 4]) # + \\\n",
    "                    # criterion(c5, lables[:, 5])\n",
    "            loss /= 5\n",
    "            global_step_val += 1\n",
    "            if global_step_val%100 ==0:\n",
    "                viz.line([loss.item()], [global_step_val%100], win='val', update='append')\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "\n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "\n",
    "                c0, c1, c2, c3, c4 = model(input)\n",
    "                if use_cuda:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.cpu().numpy(),\n",
    "                        c1.data.cpu().numpy(),\n",
    "                        c2.data.cpu().numpy(),\n",
    "                        c3.data.cpu().numpy(),\n",
    "                        c4.data.cpu().numpy(),\n",
    "                        # c5.data.cpu().numpy()\n",
    "                    ], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.numpy(),\n",
    "                        c1.data.numpy(),\n",
    "                        c2.data.numpy(),\n",
    "                        c3.data.numpy(),\n",
    "                        c4.data.numpy(),\n",
    "                        # c5.data.numpy()\n",
    "                    ], axis=1)\n",
    "\n",
    "                test_pred.append(output)\n",
    "\n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "\n",
    "    return test_pred_tta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练与验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 1.2127219400405884 \t Val loss: 1.1555243408083915\n",
      "Val Acc 0.0239\n",
      "Epoch: 1, Train loss: 1.1628801651795706 \t Val loss: 1.0511201461553574\n",
      "Val Acc 0.0222\n",
      "Epoch: 2, Train loss: 1.0816214495102565 \t Val loss: 1.0264122661352157\n",
      "Val Acc 0.0911\n",
      "Epoch: 3, Train loss: 0.8450580192307631 \t Val loss: 0.8446146462261677\n",
      "Val Acc 0.2157\n",
      "Epoch: 4, Train loss: 0.6459364933893085 \t Val loss: 0.7690737415999174\n",
      "Val Acc 0.2842\n",
      "Epoch: 5, Train loss: 0.5451873091633122 \t Val loss: 0.7232405154705047\n",
      "Val Acc 0.3366\n",
      "Epoch: 6, Train loss: 0.48524810664479934 \t Val loss: 0.694256915435195\n",
      "Val Acc 0.36\n",
      "Epoch: 7, Train loss: 0.443655635582904 \t Val loss: 0.6381269014701247\n",
      "Val Acc 0.4087\n",
      "Epoch: 8, Train loss: 0.4093269582192103 \t Val loss: 0.6366196622997522\n",
      "Val Acc 0.4147\n",
      "Epoch: 9, Train loss: 0.3854486995960275 \t Val loss: 0.5991426887959241\n",
      "Val Acc 0.4439\n",
      "Epoch: 10, Train loss: 0.36362812971447905 \t Val loss: 0.6603146039396525\n",
      "Val Acc 0.4207\n",
      "Epoch: 11, Train loss: 0.3458922279539208 \t Val loss: 0.5963065818324685\n",
      "Val Acc 0.4549\n",
      "Epoch: 12, Train loss: 0.33169141929907103 \t Val loss: 0.5798911987617612\n",
      "Val Acc 0.4687\n",
      "Epoch: 13, Train loss: 0.31605087186396125 \t Val loss: 0.5795007106326521\n",
      "Val Acc 0.4905\n",
      "Epoch: 14, Train loss: 0.3042993354994493 \t Val loss: 0.5655792835354805\n",
      "Val Acc 0.4842\n",
      "Epoch: 15, Train loss: 0.2932086790177661 \t Val loss: 0.5745116749405861\n",
      "Val Acc 0.4949\n",
      "Epoch: 16, Train loss: 0.2827163070132956 \t Val loss: 0.551364481067285\n",
      "Val Acc 0.5046\n",
      "Epoch: 17, Train loss: 0.27102429984106374 \t Val loss: 0.550891446525231\n",
      "Val Acc 0.502\n",
      "Epoch: 18, Train loss: 0.2651102330725019 \t Val loss: 0.5546752653904259\n",
      "Val Acc 0.5066\n",
      "Epoch: 19, Train loss: 0.25525016951917984 \t Val loss: 0.5518356738667936\n",
      "Val Acc 0.5122\n",
      "Epoch: 20, Train loss: 0.24539154351347436 \t Val loss: 0.5839307684376835\n",
      "Val Acc 0.5069\n",
      "Epoch: 21, Train loss: 0.2378876630058512 \t Val loss: 0.5836047125328332\n",
      "Val Acc 0.5109\n",
      "Epoch: 22, Train loss: 0.2276650509807126 \t Val loss: 0.5935014732200652\n",
      "Val Acc 0.4995\n",
      "Epoch: 23, Train loss: 0.2250234052790717 \t Val loss: 0.5647134190276265\n",
      "Val Acc 0.5169\n",
      "Epoch: 24, Train loss: 0.21760052739083766 \t Val loss: 0.6130007941834629\n",
      "Val Acc 0.496\n",
      "Epoch: 25, Train loss: 0.20614186488988342 \t Val loss: 0.6038511881809682\n",
      "Val Acc 0.5148\n",
      "Epoch: 26, Train loss: 0.20105080582170437 \t Val loss: 0.5826681126207113\n",
      "Val Acc 0.5217\n",
      "Epoch: 27, Train loss: 0.1956364793825584 \t Val loss: 0.5911199272442609\n",
      "Val Acc 0.5116\n",
      "Epoch: 28, Train loss: 0.18581543510934959 \t Val loss: 0.607817845672369\n",
      "Val Acc 0.5262\n",
      "Epoch: 29, Train loss: 0.18307941093470437 \t Val loss: 0.5998155255066231\n",
      "Val Acc 0.5161\n",
      "Epoch: 30, Train loss: 0.17840948777932983 \t Val loss: 0.6320960299023427\n",
      "Val Acc 0.5171\n",
      "Epoch: 31, Train loss: 0.17114170432308068 \t Val loss: 0.6358970236089081\n",
      "Val Acc 0.5212\n",
      "Epoch: 32, Train loss: 0.1673623696323484 \t Val loss: 0.6068691162187606\n",
      "Val Acc 0.5173\n",
      "Epoch: 33, Train loss: 0.16020580335675427 \t Val loss: 0.6535663197636604\n",
      "Val Acc 0.514\n",
      "Epoch: 34, Train loss: 0.15555010263509272 \t Val loss: 0.6439648870611563\n",
      "Val Acc 0.5224\n",
      "Epoch: 35, Train loss: 0.15030219410420978 \t Val loss: 0.6200989663137588\n",
      "Val Acc 0.5388\n",
      "Epoch: 36, Train loss: 0.14521367592640066 \t Val loss: 0.6201428649832961\n",
      "Val Acc 0.5297\n",
      "Epoch: 37, Train loss: 0.14246169529476901 \t Val loss: 0.6434717296473682\n",
      "Val Acc 0.5341\n",
      "Epoch: 38, Train loss: 0.1356499774217373 \t Val loss: 0.6915777815263718\n",
      "Val Acc 0.5162\n",
      "Epoch: 39, Train loss: 0.13129136873785563 \t Val loss: 0.6530815866664053\n",
      "Val Acc 0.5343\n"
     ]
    }
   ],
   "source": [
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "best_loss = 1000.0\n",
    "viz = Visdom()\n",
    "viz.line([0.], [0.], win='train',opts=dict(title='train loss.',\n",
    "                                                   legend=['loss']))\n",
    "viz.line([0.], [0.], win='val',opts=dict(title='val loss.',\n",
    "                                                   legend=['loss']))\n",
    "use_cuda = True\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "for epoch in range(40):\n",
    "    global_step = 3000 * epoch\n",
    "    global_step_val = 1000 * epoch\n",
    "    train_loss = train(train_loader, model, criterion, optimizer, epoch,global_step)\n",
    "    val_loss = validate(val_loader, model, criterion,global_step_val)\n",
    "\n",
    "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "    val_predict_label = predict(val_loader, model, 1)\n",
    "    val_predict_label = np.vstack([\n",
    "        val_predict_label[:, :11].argmax(1),\n",
    "        val_predict_label[:, 11:22].argmax(1),\n",
    "        val_predict_label[:, 22:33].argmax(1),\n",
    "        val_predict_label[:, 33:44].argmax(1),\n",
    "        val_predict_label[:, 44:55].argmax(1),\n",
    "        # val_predict_label[:, 55:66].argmax(1),\n",
    "    ]).T\n",
    "    val_label_pred = []\n",
    "    for x in val_predict_label:\n",
    "        val_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "\n",
    "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "\n",
    "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n",
    "    print('Val Acc', val_char_acc)\n",
    "# 记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        # print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
    "        torch.save(model.state_dict(), './output/model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 40000\n"
     ]
    }
   ],
   "source": [
    "test_path = glob.glob('./input/test/*.png')\n",
    "test_path.sort()\n",
    "test_label = [[1]] * len(test_path)\n",
    "print(len(test_path), len(test_label))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    # transforms.RandomCrop((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])),\n",
    "    batch_size=40,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 55)\n"
     ]
    }
   ],
   "source": [
    "# 加载保存的最优模型\n",
    "model.load_state_dict(torch.load('./output/model.pt'))\n",
    "\n",
    "test_predict_label = predict(test_loader, model, 1)\n",
    "print(test_predict_label.shape)\n",
    "\n",
    "test_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\n",
    "test_predict_label = np.vstack([\n",
    "    test_predict_label[:, :11].argmax(1),\n",
    "    test_predict_label[:, 11:22].argmax(1),\n",
    "    test_predict_label[:, 22:33].argmax(1),\n",
    "    test_predict_label[:, 33:44].argmax(1),\n",
    "    test_predict_label[:, 44:55].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "\n",
    "import pandas as pd\n",
    "df_submit = pd.read_csv('./input/mchar_sample_submit_A.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('./output/submit.csv', index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}